<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>ðŸŒ¿ Palma AR (CÃ¢mera Traseira)</title>

  <!-- A-Frame -->
  <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>

  <!-- MediaPipe Hands -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <style>
    body, html { margin:0; overflow:hidden; background:black; }
    video, canvas { position:fixed; left:0; top:0; width:100vw; height:100vh; object-fit:cover; }
    canvas { z-index:1; }
    a-scene { position:fixed; top:0; left:0; width:100vw; height:100vh; z-index:2; pointer-events:none; }
  </style>
</head>

<body>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="output_canvas"></canvas>

  <a-scene embedded vr-mode-ui="enabled: false">
    <a-entity id="model"
      gltf-model="url(assets/onion_shrub.glb)"
      visible="false"
      position="0 0 -2"
      scale="0.3 0.3 0.3"
      animation-mixer="clip:*; loop: repeat;">
    </a-entity>
    <a-entity camera></a-entity>
  </a-scene>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const model = document.getElementById('model');

    // Configura MediaPipe Hands
    const hands = new Hands({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}` });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.5
    });
    hands.onResults(onResults);

    // FunÃ§Ã£o que inicia a cÃ¢mera traseira manualmente
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { ideal: 'environment' } },
          audio: false
        });
        videoElement.srcObject = stream;
        videoElement.onloadedmetadata = () => videoElement.play();
        requestAnimationFrame(processFrame);
        console.log('âœ… CÃ¢mera traseira iniciada com sucesso!');
      } catch (err) {
        console.error('âŒ Erro ao acessar a cÃ¢mera:', err);
      }
    }

    async function processFrame() {
      await hands.send({ image: videoElement });
      requestAnimationFrame(processFrame);
    }

    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const hand = results.multiHandLandmarks[0];

        // Detecta se a palma estÃ¡ aberta
        const openPalm =
          hand[8].y < hand[6].y &&
          hand[12].y < hand[10].y &&
          hand[16].y < hand[14].y &&
          hand[20].y < hand[18].y;

        if (openPalm) {
          model.setAttribute('visible', 'true');
        } else {
          model.setAttribute('visible', 'false');
        }

        drawConnectors(canvasCtx, hand, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 3 });
        drawLandmarks(canvasCtx, hand, { color: '#FF0000', lineWidth: 1 });
      } else {
        model.setAttribute('visible', 'false');
      }

      canvasCtx.restore();
    }

    // Inicia tudo
    startCamera();
  </script>
</body>
</html>
