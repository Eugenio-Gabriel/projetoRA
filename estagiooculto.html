<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>ðŸŒ¼ Flor que nasce na palma</title>

  <!-- A-Frame + AR.js -->
  <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>

  <!-- MediaPipe Hands -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <style>
    html, body { margin: 0; overflow: hidden; }
    a-scene {
      position: fixed;
      top: 0; left: 0;
      width: 100vw; height: 100vh;
    }
    #arjs-video {
      filter: brightness(1.1) contrast(1.05) saturate(1.2);
      object-fit: cover;
      transform: scaleX(-1);
    }
  </style>
</head>

<body>
  <a-scene embedded arjs="sourceType: webcam; videoTexture: true; debugUIEnabled: false;">
    <a-entity id="model"
      gltf-model="url(assets/florzinha.glb)"
      visible="false"
      position="0 0 -2"
      scale="0.1 0.1 0.1">
    </a-entity>
    <a-entity camera></a-entity>
  </a-scene>

  <script>
    const hands = new Hands({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}` });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.6
    });

    const model = document.getElementById('model');
    const video = document.querySelector('video');

    video.addEventListener('loadeddata', () => {
      console.log('âœ… CÃ¢mera AR.js pronta');
      processFrames();
    });

    async function processFrames() {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      async function loop() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        await hands.send({ image: canvas });
        requestAnimationFrame(loop);
      }

      // FunÃ§Ã£o para medir abertura da mÃ£o
      function getHandOpenness(hand) {
        const base = hand[0];  // pulso
        const tip = hand[9];   // centro da palma (entre mÃ©dio e anelar)
        const dist = Math.sqrt(
          Math.pow(tip.x - base.x, 2) +
          Math.pow(tip.y - base.y, 2) +
          Math.pow(tip.z - base.z, 2)
        );
        return dist; // distÃ¢ncia ~ grau de abertura
      }

      let currentScale = 0.1;

      hands.onResults(results => {
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
          const hand = results.multiHandLandmarks[0];
          const openness = getHandOpenness(hand);

          // Define um limite de abertura (ajusta conforme teu teste)
          const min = 0.05; // mÃ£o fechada
          const max = 0.15; // mÃ£o bem aberta
          let t = (openness - min) / (max - min);
          t = Math.max(0, Math.min(1, t)); // limita entre 0 e 1

          // Interpola suavemente o tamanho entre 0 e 0.4
          const targetScale = 0.1 + t * 0.4;
          currentScale += (targetScale - currentScale) * 0.1; // suaviza o movimento

          model.setAttribute('scale', `${currentScale} ${currentScale} ${currentScale}`);
          model.setAttribute('visible', true);
        } else {
          model.setAttribute('visible', false);
        }
      });

      loop();
    }
  </script>
</body>
</html>
